{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nnTplNQjQqSd"
   },
   "source": [
    "# Lab: Stock Prediction<br><font size=\"4\">**Portfolio Management**</font>\n",
    "***Series: Deep learning with Tensorflow 2 and Keras***<br>\n",
    "*Prepared by: Jacob Cybulski*<br>\n",
    "*Date: Sept 2020*\n",
    "\n",
    "***Overview:***<br>\n",
    "*This notebook demonstrates how to use Recurrent Neural Network (such as LSTM and GRU) to predict a stock value based on the movement of several stocks in a portfolio, e.g. HPQ, GOOGL, MSFT, IBM, INTC, ADBE, AMZN and AAPL, the last one we will be trying to predict.*\n",
    "\n",
    "<hr style=\"height:1px;border:none;color:#333;background-color:#333;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mertjWzkQqSd"
   },
   "source": [
    "**Enter your name and student number below, e.g.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "r46UBr76QqSe"
   },
   "source": [
    "<font color='red'>**Your name and student number go here, e.g. Jacob Cybulski (12345678)**</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SBPzC5QQQqSe"
   },
   "source": [
    "# Lab exercises / Assignment 3 Part C"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SqNV-n2hQqSf"
   },
   "source": [
    "**This lab exercise and assignment follow the example demonstrated in lecture.<br>\n",
    "It's aim is to create a new model and alter it to improve performance.**\n",
    "\n",
    "*Undertake the following tasks.*\n",
    "\n",
    "1. Run this notebook and record results (multivariate to predict IBM), report\n",
    "2. Run this notebook in a univariate mode (use IBM but also try another stock), compare and report\n",
    "3. Optimise multivariate network using various optimisers and parameters, compare and report\n",
    "4. Use multiple stocks as part of the label, experiment with different network architectures, report\n",
    "5. Then optimise the selected architecture for the multi-label case, compare and report\n",
    "   - Does it matter if the custom loss function was used or not?\n",
    "6. Check if your best network overall is capable of predicting 7 days ahead (instead of 2), report\n",
    "7. Provide analysis and recommendations for the best solution in \"portfolio management\"\n",
    "8. Reflect on your experience gained in module 3 on Deep Learning\n",
    "9. Challenges for Python hackers (just for glory not marks)\n",
    "   - Calculate errors in true MAE units (unscaled)\n",
    "   - Exclude interpolated data from error calculation (these are not true data)\n",
    "\n",
    "*Keep the record of your activities, models and results in the section at the*\n",
    "<font color=\"red\">**end of this notebook**</font>.\n",
    "<hr style=\"height:1px;border:none;color:#333;background-color:#333;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zkctaewxQqSf"
   },
   "source": [
    "### Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0r9dHpbwQqSg"
   },
   "source": [
    "*General purpose libraries*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1571,
     "status": "ok",
     "timestamp": 1600920681983,
     "user": {
      "displayName": "Fatima Shiri",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjAn6eOEmJe2cvlJCvEwFwH_fJ_ccdyIze5N8aY6L8=s64",
      "userId": "07581629474593911406"
     },
     "user_tz": -600
    },
    "id": "P9ZLANffQqSg"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mL4F8mMUQqSj"
   },
   "source": [
    "*Sci-kit Learn libs*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1567,
     "status": "ok",
     "timestamp": 1600920681984,
     "user": {
      "displayName": "Fatima Shiri",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjAn6eOEmJe2cvlJCvEwFwH_fJ_ccdyIze5N8aY6L8=s64",
      "userId": "07581629474593911406"
     },
     "user_tz": -600
    },
    "id": "exWsKjoFQqSj"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qrBao9cCQqSl"
   },
   "source": [
    "*Deep learning libraries*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1314,
     "status": "ok",
     "timestamp": 1600920681985,
     "user": {
      "displayName": "Fatima Shiri",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjAn6eOEmJe2cvlJCvEwFwH_fJ_ccdyIze5N8aY6L8=s64",
      "userId": "07581629474593911406"
     },
     "user_tz": -600
    },
    "id": "K56FD8kCQqSm"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import metrics\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Input, Dense, GRU, Embedding, BatchNormalization\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Activation\n",
    "from tensorflow.keras.optimizers import Adam, Nadam, RMSprop, SGD, Adadelta\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, TensorBoard, ReduceLROnPlateau\n",
    "from tensorflow.keras.backend import square, mean\n",
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GqLMnALpQqSn"
   },
   "source": [
    "*Options to control display of information*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1066,
     "status": "ok",
     "timestamp": 1600920682270,
     "user": {
      "displayName": "Fatima Shiri",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjAn6eOEmJe2cvlJCvEwFwH_fJ_ccdyIze5N8aY6L8=s64",
      "userId": "07581629474593911406"
     },
     "user_tz": -600
    },
    "id": "GJivPAibQqSo"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "plt.rcParams[\"figure.figsize\"] = [10, 5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "O_lKjza1QqSq"
   },
   "source": [
    "*Check GPU on this machine*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1032,
     "status": "ok",
     "timestamp": 1600920682773,
     "user": {
      "displayName": "Fatima Shiri",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjAn6eOEmJe2cvlJCvEwFwH_fJ_ccdyIze5N8aY6L8=s64",
      "userId": "07581629474593911406"
     },
     "user_tz": -600
    },
    "id": "CzGVVx6GQqSq",
    "outputId": "a918871e-e1ec-4b16-9c6d-640ea5bc931d"
   },
   "outputs": [],
   "source": [
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1pgjOdCwQqSs"
   },
   "source": [
    "### Utilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Kigkbp0XQqSt"
   },
   "source": [
    "*Allows display of data frames side by side*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4083,
     "status": "ok",
     "timestamp": 1600920686827,
     "user": {
      "displayName": "Fatima Shiri",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjAn6eOEmJe2cvlJCvEwFwH_fJ_ccdyIze5N8aY6L8=s64",
      "userId": "07581629474593911406"
     },
     "user_tz": -600
    },
    "id": "_PJ8a-N9QqSt"
   },
   "outputs": [],
   "source": [
    "from IPython.display import display_html\n",
    "def display_side_by_side(*args):\n",
    "    html_str=''\n",
    "    for df in args:\n",
    "        html_str+=df.to_html()\n",
    "    display_html(html_str.replace('table','table style=\"display:inline\"'),raw=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dG4pLJwpQqSv"
   },
   "source": [
    "*Collect history*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3441,
     "status": "ok",
     "timestamp": 1600920686828,
     "user": {
      "displayName": "Fatima Shiri",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjAn6eOEmJe2cvlJCvEwFwH_fJ_ccdyIze5N8aY6L8=s64",
      "userId": "07581629474593911406"
     },
     "user_tz": -600
    },
    "id": "xJ5-SMwmQqSw"
   },
   "outputs": [],
   "source": [
    "# Initiates collections of model performance\n",
    "def start_hist():\n",
    "    return {}\n",
    "\n",
    "# Adds more performance indicators to history\n",
    "def collect_hist(accum_hist, next_hist):\n",
    "    # Get all keys\n",
    "    keys = list(next_hist.keys())\n",
    "    for k in keys:\n",
    "        if k in accum_hist:\n",
    "            accum_hist[k].extend(next_hist[k])\n",
    "        else:\n",
    "            accum_hist[k] = next_hist[k]\n",
    "    return accum_hist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "n7yMFuAwQqSx"
   },
   "source": [
    "*Plotting history*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2336,
     "status": "ok",
     "timestamp": 1600920686828,
     "user": {
      "displayName": "Fatima Shiri",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjAn6eOEmJe2cvlJCvEwFwH_fJ_ccdyIze5N8aY6L8=s64",
      "userId": "07581629474593911406"
     },
     "user_tz": -600
    },
    "id": "P6ZRptLEQqSy"
   },
   "outputs": [],
   "source": [
    "def plot_hist(h, xsize=6, ysize=5):\n",
    "    # Prepare plotting\n",
    "    fig_size = plt.rcParams[\"figure.figsize\"]\n",
    "    plt.rcParams[\"figure.figsize\"] = [xsize, ysize]\n",
    "    \n",
    "    # Get training and validation keys\n",
    "    ks = list(h.keys())\n",
    "    n2 = math.floor(len(ks)/2)\n",
    "    train_keys = ks[0:n2]\n",
    "    valid_keys = ks[n2:2*n2]\n",
    "    \n",
    "    # summarize history for different metrics\n",
    "    for i in range(n2):\n",
    "        plt.plot(h[train_keys[i]])\n",
    "        plt.plot(h[valid_keys[i]])\n",
    "        plt.title('Training vs Validation '+train_keys[i])\n",
    "        plt.ylabel(train_keys[i])\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "        plt.draw()\n",
    "        plt.show()\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JnBy_hp5QqSz"
   },
   "source": [
    "### Load data\n",
    "\n",
    "*All available stock data*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4024,
     "status": "ok",
     "timestamp": 1600920689254,
     "user": {
      "displayName": "Fatima Shiri",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjAn6eOEmJe2cvlJCvEwFwH_fJ_ccdyIze5N8aY6L8=s64",
      "userId": "07581629474593911406"
     },
     "user_tz": -600
    },
    "id": "sw-FBAhNQvZI",
    "outputId": "41bcfccf-f9c7-42ba-acaa-6a7e09f992dc"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 272
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3698,
     "status": "ok",
     "timestamp": 1600920689255,
     "user": {
      "displayName": "Fatima Shiri",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjAn6eOEmJe2cvlJCvEwFwH_fJ_ccdyIze5N8aY6L8=s64",
      "userId": "07581629474593911406"
     },
     "user_tz": -600
    },
    "id": "-GRMpL3WQqS0",
    "outputId": "c4e82bd7-d463-4054-ea00-b3d1d197a7c0"
   },
   "outputs": [],
   "source": [
    "stock = pd.read_csv('../input/stocks.csv')\n",
    "stock['Date'] = pd.to_datetime(stock['Date'])\n",
    "print('Stock data shape: ', stock.shape)\n",
    "print('Date from: ', stock['Date'].min(), 'to: ', stock['Date'].max())\n",
    "print('Day from: ', stock['Day'].min(), 'to: ', stock['Day'].max())\n",
    "print('Number of records:', stock.shape[0], 'max-min day:', stock['Day'].max()-stock['Day'].min()+1)\n",
    "stock.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mGln1tQLQqS2"
   },
   "source": [
    "*Plot a couple of stocks*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 352
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4643,
     "status": "ok",
     "timestamp": 1600920690802,
     "user": {
      "displayName": "Fatima Shiri",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjAn6eOEmJe2cvlJCvEwFwH_fJ_ccdyIze5N8aY6L8=s64",
      "userId": "07581629474593911406"
     },
     "user_tz": -600
    },
    "id": "8UCXwgSzQqS2",
    "outputId": "0a854fc6-4097-4f9a-dd92-090e35286984"
   },
   "outputs": [],
   "source": [
    "ax1 = stock['AAPL'].plot(color=\"lightblue\", alpha=0.9)\n",
    "ax1.set(xlabel='Days', ylabel='Stock Value')\n",
    "stock['IBM'].plot(color=\"red\", alpha=0.5, ax=ax1)\n",
    "plt.legend(['AAPL', 'BLUE'], loc='upper left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rVxOb8OJQqS4"
   },
   "source": [
    "## Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "B4W022oKQqS4"
   },
   "source": [
    "### Data selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zg5jCL4FQqS5"
   },
   "source": [
    "*Select date, day and stocks for the portfolio, remember that Date and Day are needed here.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 503
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 810,
     "status": "ok",
     "timestamp": 1600920421491,
     "user": {
      "displayName": "Fatima Shiri",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjAn6eOEmJe2cvlJCvEwFwH_fJ_ccdyIze5N8aY6L8=s64",
      "userId": "07581629474593911406"
     },
     "user_tz": -600
    },
    "id": "n0AKO4VhQqS5",
    "outputId": "6f745dff-30f6-4288-9362-33b3b8dfe5f3"
   },
   "outputs": [],
   "source": [
    "stocks = ['Date', 'Day', 'AAPL', 'ADBE', 'AMZN', 'GOOGL', 'IBM', 'MSFT'] # Try just IBM\n",
    "labels = ['IBM', 'AAPL'] # Try others, e.g. AAPL or HPQ (but add it above)\n",
    "horizon = 2\n",
    "\n",
    "# Select raw_portfolio\n",
    "raw_portfolio = stock[stocks]\n",
    "\n",
    "print('Selected stocks: ', ', '.join(stocks))\n",
    "print('Prediction target: ', labels)\n",
    "print('Selected data shape: ', raw_portfolio.shape)\n",
    "raw_portfolio.describe(include='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8UEWsjWwQqS7"
   },
   "source": [
    "### Imputation of missing values (if needed)\n",
    "\n",
    "*Note that we need to check if the stock data has any missing data.*<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 737,
     "status": "ok",
     "timestamp": 1600920421939,
     "user": {
      "displayName": "Fatima Shiri",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjAn6eOEmJe2cvlJCvEwFwH_fJ_ccdyIze5N8aY6L8=s64",
      "userId": "07581629474593911406"
     },
     "user_tz": -600
    },
    "id": "CVZzyefBQqS7",
    "outputId": "0f3256da-f6a4-4279-c0a6-4f412b64ab2f"
   },
   "outputs": [],
   "source": [
    "print('Records:\\t', len(raw_portfolio))\n",
    "missing = raw_portfolio.isnull().sum()\n",
    "print(missing.sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dXo3R3sLQqTA"
   },
   "source": [
    "### Resample and interpolate missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pc6UsH1RQqTA"
   },
   "source": [
    "*We need to resample the contents of all Pandas (sub) data-frames by removing empty rows and columns (if any),<br>\n",
    "and then up-sampling the data frame by interpolating records in 1-day intervals.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tqYvg6EyQqTB"
   },
   "outputs": [],
   "source": [
    "def stock_resample(df):\n",
    "\n",
    "    # Remove all empty rows.\n",
    "    df_res = df.dropna(how='all')\n",
    "    \n",
    "    # Create a sorted index from date\n",
    "    df_res['Date'] = pd.to_datetime(df_res['Date'])\n",
    "    df_res.index = df_res['Date']\n",
    "    df_res.sort_index(inplace=True)\n",
    "    del df_res['Date']\n",
    "\n",
    "    # Upsample so the time-series has data for every day\n",
    "    df_res = df_res.resample('D')\n",
    "\n",
    "    # Fill in missing values by interpolating in between existing records\n",
    "    df_res = df_res.interpolate(method='values')\n",
    "\n",
    "    # Remove any empty rows that may have been created in this process\n",
    "    df_res = df_res.dropna(how='all')\n",
    "    \n",
    "    # Columns no longer needed\n",
    "    del df_res['Day']\n",
    "\n",
    "    return df_res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "obqhMh0OQqTD"
   },
   "source": [
    "*Resample all stocks*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-mBTY1L_QqTE",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "portfolio_x = stock_resample(raw_portfolio)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "x_Eh4uShQqTG"
   },
   "source": [
    "*Observe missing dates in the original table - we should have no missing values*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 560,
     "status": "ok",
     "timestamp": 1600920423571,
     "user": {
      "displayName": "Fatima Shiri",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjAn6eOEmJe2cvlJCvEwFwH_fJ_ccdyIze5N8aY6L8=s64",
      "userId": "07581629474593911406"
     },
     "user_tz": -600
    },
    "id": "GQWsYDy_QqTG",
    "outputId": "3c41430f-c95c-40d5-a78a-597d3d744cb1"
   },
   "outputs": [],
   "source": [
    "raw_portfolio[(raw_portfolio['Date'] >= '2010-01-07') & (raw_portfolio['Date'] <= '2010-01-12')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2mHTCdREQqTI"
   },
   "source": [
    "*Observe that missing values have been interpolated*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 266
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 803,
     "status": "ok",
     "timestamp": 1600920424317,
     "user": {
      "displayName": "Fatima Shiri",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjAn6eOEmJe2cvlJCvEwFwH_fJ_ccdyIze5N8aY6L8=s64",
      "userId": "07581629474593911406"
     },
     "user_tz": -600
    },
    "id": "qnLgejVJQqTI",
    "outputId": "fab732fe-7cbc-4581-aff9-c9e8d5832f79"
   },
   "outputs": [],
   "source": [
    "portfolio_x['2010-01-07':'2010-01-12']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-u4-_9eAQqTJ"
   },
   "source": [
    "*The labels come from the original data but time-shifted to the left (past)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BeTI7c8DQqTK"
   },
   "outputs": [],
   "source": [
    "portfolio_y = portfolio_x[labels].shift(-horizon)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1oHsRxUFQqTM"
   },
   "source": [
    "*As we shift data to the left (past), examples from the beginning of the series will drop off, and those from the end will become undefined*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 328
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 964,
     "status": "ok",
     "timestamp": 1600920425599,
     "user": {
      "displayName": "Fatima Shiri",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjAn6eOEmJe2cvlJCvEwFwH_fJ_ccdyIze5N8aY6L8=s64",
      "userId": "07581629474593911406"
     },
     "user_tz": -600
    },
    "id": "ibkOJUJcQqTM",
    "outputId": "4e0ac449-18be-4ee4-8a56-6a72627d0902"
   },
   "outputs": [],
   "source": [
    "display_side_by_side(\n",
    "    pd.concat([portfolio_x[labels].head(horizon + 5)], keys=['Original series'], axis=1),\n",
    "    pd.concat([portfolio_y.head(5)], keys=['Start of new series'], axis=1),\n",
    "    pd.concat([portfolio_y.tail(horizon+5)], keys=['End of new series'], axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RU9UQMJJQqTO"
   },
   "source": [
    "### Data preparation for Keras RNN (NumPy arrays)\n",
    "\n",
    "*We now convert the Pandas data-frames to NumPy arrays that can be input to the neural network. We also remove the last part of the numpy arrays, because the target-data has `NaN` for the shifted period, and we only want to have valid data and we need the same array-shapes for the input- and output-data.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 834,
     "status": "ok",
     "timestamp": 1600920752435,
     "user": {
      "displayName": "Fatima Shiri",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjAn6eOEmJe2cvlJCvEwFwH_fJ_ccdyIze5N8aY6L8=s64",
      "userId": "07581629474593911406"
     },
     "user_tz": -600
    },
    "id": "Jo2q1wBlRs1X",
    "outputId": "6894f509-ee72-44d7-a6a1-e5cef7d92d77"
   },
   "outputs": [],
   "source": [
    "# Correct predictors x and targets/labels y for the horizon shift\n",
    "x_data = portfolio_x.values[0:-horizon]\n",
    "y_data = portfolio_y.values[:-horizon]\n",
    "\n",
    "# Calculate training and testing partition sizes\n",
    "num_data = len(x_data)\n",
    "train_split = 0.7\n",
    "num_train = int(train_split * num_data)\n",
    "num_test = num_data - num_train\n",
    "\n",
    "# Define boundaries for training and testing\n",
    "x_train = x_data[0:num_train]\n",
    "x_test = x_data[num_train:]\n",
    "y_train = y_data[0:num_train]\n",
    "y_test = y_data[num_train:]\n",
    "\n",
    "# Identify time events to be used in training\n",
    "num_x_events = x_data.shape[1]\n",
    "num_y_events = y_data.shape[1]\n",
    "\n",
    "print(\"Original x shape:\", x_data.shape, \", New x shape:\", x_train.shape, x_test.shape)\n",
    "print(\"Original y shape:\", y_data.shape, \", New y shape:\", y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SbzFmUU5RVMQ"
   },
   "source": [
    "### Scale data\n",
    "\n",
    "*Before this data can be used by neural net, its X and Y values need scaling to [0:1] range.*\n",
    "*We will need to estimate the future stock growth across the portfolio and scale data to a smaller range, e.g. [0:0.4], then we will apply the scaler to all new data without any clipping (which could cause problems).*<br>\n",
    "<font color=\"red\">*We must check that the new/test data does not go (much) over the [0:1] range!*</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yIzRLYWGQqTT"
   },
   "outputs": [],
   "source": [
    "print(\"Before train x scaling - Min:\", np.min(x_train), \", Max:\", np.max(x_train))\n",
    "print(\"Before test x scaling - Min:\", np.min(x_test), \", Max:\", np.max(x_test))\n",
    "x_scaler = MinMaxScaler(feature_range=(0, 0.3), copy=True)\n",
    "x_train_scaled = x_scaler.fit_transform(x_train).clip(0, 1)\n",
    "x_test_scaled = x_scaler.transform(x_test).clip(0, 1)\n",
    "print(\"After train x scaling - Min:\", np.min(x_train_scaled), \", Max:\", np.max(x_train_scaled))\n",
    "print(\"After test x scaling - Min:\", np.min(x_test_scaled), \", Max:\", np.max(x_test_scaled))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "o5TLcUdLQqTV"
   },
   "outputs": [],
   "source": [
    "print(\"Before train y scaling - Min:\", np.min(y_train), \", Max:\", np.max(y_train))\n",
    "print(\"Before test y scaling - Min:\", np.min(y_test), \", Max:\", np.max(y_test))\n",
    "y_scaler = x_scaler\n",
    "y_train_scaled = y_scaler.fit_transform(y_train)\n",
    "y_test_scaled = y_scaler.transform(y_test)\n",
    "print(\"After train y scaling - Min:\", np.min(y_train_scaled), \", Max:\", np.max(y_train_scaled))\n",
    "print(\"After test y scaling - Min:\", np.min(y_test_scaled), \", Max:\", np.max(y_test_scaled))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print a week of Xs and Ys side by side\n",
    "display_side_by_side(\n",
    "    pd.concat([pd.DataFrame(x_train_scaled, columns=portfolio_x.columns).head(7)], keys=['X'], axis=1),\n",
    "    pd.concat([pd.DataFrame(y_train_scaled, columns=portfolio_y.columns).head(7)], keys=['Y'], axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "A8ntAmiaQqTX"
   },
   "source": [
    "## Create a data generator\n",
    "\n",
    "*As the training-data could potentially have 1000s of observations, so instead of training the neural net on the complete sequences, we will use a generator function to create batches of shorter sub-sequences picked at random from training data.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CLx5TyIrQqTX"
   },
   "source": [
    "*Use a large batch-size to keep the GPU busy. Or we can pick a smaller batch size to improve accuracy and performance. You may have to adjust this number depending on your GPU, its RAM and your sequence_length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6Il8aPU9QqTX"
   },
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "sequence_length = 42 # 6 weeks x 7 days"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "39ihNP-1QqTZ"
   },
   "source": [
    "*Generator function*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vbLbrbYNQqTZ"
   },
   "outputs": [],
   "source": [
    "def batch_generator(batch_size, sequence_length, nt, nx, ny):\n",
    "    while True:\n",
    "        # Allocate a new array for the batch of input-events.\n",
    "        x_shape = (batch_size, sequence_length, nx)\n",
    "        x_batch = np.zeros(shape=x_shape, dtype=np.float16)\n",
    "\n",
    "        # Allocate a new array for the batch of output-events.\n",
    "        y_shape = (batch_size, sequence_length, ny)\n",
    "        y_batch = np.zeros(shape=y_shape, dtype=np.float16)\n",
    "\n",
    "        # Fill the batch with random sequences of data.\n",
    "        for i in range(batch_size):\n",
    "            # Get a random start-index.\n",
    "            # This points somewhere into the training-data.\n",
    "            idx = np.random.randint(nt - sequence_length)\n",
    "            \n",
    "            # Copy the sequences of data starting at this index.\n",
    "            x_batch[i] = x_train_scaled[idx:idx+sequence_length]\n",
    "            y_batch[i] = y_train_scaled[idx:idx+sequence_length]\n",
    "        \n",
    "        yield (x_batch, y_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PFp6nDX8QqTb"
   },
   "source": [
    "*Create the batch-generator*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NnKHyv3kQqTb"
   },
   "outputs": [],
   "source": [
    "# fix random seed for (near) reproducibility\n",
    "np.random.seed(7)\n",
    "\n",
    "generator = batch_generator(batch_size=batch_size, sequence_length=sequence_length, \n",
    "                            nt=num_train, nx=num_x_events, ny=num_y_events)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gi29aSRbQqTd"
   },
   "source": [
    "*Create validation set*\n",
    "\n",
    "Note: Model validation will be performed after each epoch and when the model improves its weights will be saved.<br>\n",
    "For training, we will use the batch-generator, however, for validation we will use the entire sequence, i.e. including x and y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BhwYq5-kQqTd"
   },
   "outputs": [],
   "source": [
    "validation_data = (np.expand_dims(x_test_scaled, axis=0),\n",
    "                   np.expand_dims(y_test_scaled, axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UFcyZydzQqTf"
   },
   "source": [
    "*Test generator*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 564
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1285,
     "status": "ok",
     "timestamp": 1600920430729,
     "user": {
      "displayName": "Fatima Shiri",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjAn6eOEmJe2cvlJCvEwFwH_fJ_ccdyIze5N8aY6L8=s64",
      "userId": "07581629474593911406"
     },
     "user_tz": -600
    },
    "id": "VZI696y3QqTf",
    "outputId": "1525f95c-f1ce-48e1-d649-83f30e3a9e6d"
   },
   "outputs": [],
   "source": [
    "batch = 0  # Some sequence in the batch\n",
    "event = 0  # Some event from input-events\n",
    "\n",
    "x_batch, y_batch = next(generator)\n",
    "print('X batch shape =', x_batch.shape, ', Input size =', x_batch.shape[1]*x_batch.shape[2])\n",
    "print('Y batch shape =', y_batch.shape, ', Output size =', y_batch.shape[1]*y_batch.shape[2])\n",
    "\n",
    "x_seq = x_batch[batch, :, event]\n",
    "y_seq = y_batch[batch, :, event]\n",
    "plt.plot(x_seq)\n",
    "plt.plot(y_seq)\n",
    "plt.title('Time Series Batch: Training (past) vs Labels (future)')\n",
    "plt.ylabel('Measurement')\n",
    "plt.xlabel('Time')\n",
    "plt.legend(['Training (x)', 'Labels (y)'], loc='upper left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "trg-dFCxQqTh"
   },
   "source": [
    "## Create the Recurrent Neural Network\n",
    "\n",
    "*We will create the forecasting model using a Recurrent Neural Network, such as vanilla RNN, LSTM and GRU.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CU-UWavdQqTh"
   },
   "source": [
    "*Network parameters: note that there is 3600 training examples and our sequence is 42 examples in length. As the batch-size is 256 sequences, each step in an epoch will run 256x42 examples. So the possibility of overtraining is huge unless we control these parameters carefully.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OldjXESjQqTh"
   },
   "outputs": [],
   "source": [
    "epochs = 50\n",
    "steps_per_epoch = 60\n",
    "warmup_steps = 7 # For custom loss function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "e2r8W0P0QqTj"
   },
   "source": [
    "### Loss Function\n",
    "\n",
    "*We will use a custom `Mean Squared Error (MSE)` as the loss-function.*\n",
    "\n",
    "The function will deal in a special way with events at the beginning of a sequence. As the model has seen input-events for a few time-steps only, so its generated output may be very inaccurate. Using the standard loss function which utilises the early time-steps may cause the model to distort its later output. We therefore give the model a \"warmup-period\" of `warmup_steps` time-steps where we don't use its accuracy in the loss-function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2R3N0UUoQqTj"
   },
   "outputs": [],
   "source": [
    "# The shape of both input tensors are: [batch_size, sequence_length, num_y_events]\n",
    "def loss_mse_warmup(y_true, y_pred):\n",
    "    # Ignore the \"warmup\" parts of the sequences\n",
    "    y_true_slice = y_true[:, warmup_steps:, :]\n",
    "    y_pred_slice = y_pred[:, warmup_steps:, :]\n",
    "    mse = mean(square(y_true_slice - y_pred_slice))   \n",
    "    return mse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ubL45mB9QqTl"
   },
   "source": [
    "### RNN Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3pgxL7ygQqTl"
   },
   "source": [
    "<font color=\"red\">**Add more models here as needed**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xL2QZghfQqTl"
   },
   "outputs": [],
   "source": [
    "def rnn_model_gru_sigmoid_1(num_x_events, num_y_events):\n",
    "    model = Sequential()\n",
    "    model.add(GRU(units=256,\n",
    "                  return_sequences=True,\n",
    "                  input_shape=(None, num_x_events,)))\n",
    "    model.add(Dense(num_y_events, activation='sigmoid'))\n",
    "    model.summary()\n",
    "    return(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rnn_model_gru_sigmoid_2(num_x_events, num_y_events):\n",
    "    model = Sequential()\n",
    "    model.add(GRU(units=512,\n",
    "                  return_sequences=True,\n",
    "                  input_shape=(None, num_x_events,)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(num_y_events, activation='sigmoid'))\n",
    "    model.summary()\n",
    "    return(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ckS1CISyQqTn"
   },
   "outputs": [],
   "source": [
    "def rnn_model_gru_layers(num_x_events, num_y_events):\n",
    "    model = Sequential()\n",
    "    model.add(GRU(units=512,\n",
    "                  return_sequences=True,\n",
    "                  input_shape=(None, num_x_events,)))\n",
    "    model.add(GRU(units=256,\n",
    "                  return_sequences=True))\n",
    "    model.add(Dense(num_y_events, activation='sigmoid'))\n",
    "    model.summary()\n",
    "    return(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "C6NCBFJlQqTo"
   },
   "outputs": [],
   "source": [
    "# Alternatively, we can use a linear activation function to allow for the output \n",
    "# to take on arbitrary values. However, when more layers are in use, it may be \n",
    "# necessary to initialize weights with smaller values to avoid `NaN` values\n",
    "\n",
    "from tensorflow.python.keras.initializers import RandomUniform\n",
    "\n",
    "# This model will keep very small weights to start with\n",
    "def rnn_model_gru_linear(num_x_events, num_y_events):\n",
    "    init = RandomUniform(minval=-0.05, maxval=0.05)\n",
    "    model = Sequential()\n",
    "    model.add(GRU(units=512,\n",
    "                    return_sequences=True,\n",
    "                    input_shape=(None, num_x_events,)))\n",
    "    model.add(Dense(num_y_events, activation='linear',\n",
    "                    kernel_initializer=init))\n",
    "    model.summary()\n",
    "    return(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vvHaTIOxQqTq"
   },
   "outputs": [],
   "source": [
    "# More custom models go here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9WFL1rMmQqTs"
   },
   "source": [
    "### Create and compile the model\n",
    "\n",
    "*Define a few optimizers to chose from. Note that this is the initial learning rate, which will be dynamic.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 221
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1164,
     "status": "ok",
     "timestamp": 1600920434634,
     "user": {
      "displayName": "Fatima Shiri",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjAn6eOEmJe2cvlJCvEwFwH_fJ_ccdyIze5N8aY6L8=s64",
      "userId": "07581629474593911406"
     },
     "user_tz": -600
    },
    "id": "xw5E0LqeQqTs",
    "outputId": "bab54b57-72b7-4c46-9c0e-96230e12871d"
   },
   "outputs": [],
   "source": [
    "opt_sgd_1 = SGD(lr=0.01, momentum=0.0, nesterov=False)\n",
    "opt_sgd_2 = SGD(lr=0.05, momentum=0.1, nesterov=False) # Good results with ReduceLROnPlateau\n",
    "opt_rmsprop_1 = RMSprop(lr=0.005, rho=0.9, decay=0.5, epsilon=1e-07)\n",
    "opt_rmsprop_2 = RMSprop(lr=0.01, rho=0.9, decay=0.1, epsilon=1e-07)\n",
    "opt_adadelta_1 = Adadelta(lr=0.001, rho=0.95, epsilon=1e-07)\n",
    "opt_adadelta_2 = Adadelta(lr=0.01, rho=0.99, epsilon=1e-07)\n",
    "opt_adam_1 = Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-07)\n",
    "opt_adam_2 = Adam(lr=0.005, beta_1=0.85, beta_2=0.999, epsilon=1e-07)\n",
    "opt_nadam = Nadam(lr=0.001, beta_1=0.7, beta_2=0.95, epsilon=1e-07)\n",
    "\n",
    "# Start collecting history, in case we train the model iteratively\n",
    "rnn_hist = start_hist()\n",
    "\n",
    "model = rnn_model_gru_sigmoid_2(num_x_events, num_y_events)\n",
    "model.compile(loss=loss_mse_warmup, optimizer=opt_sgd_2, metrics=[metrics.mae])\n",
    "# model.compile(loss='mean_squared_error', optimizer=opt_sgd_2, metrics=[metrics.mae])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FDpeBNWFQqTu"
   },
   "source": [
    "### Callback functions\n",
    "\n",
    "*During training we want to save checkpoints and log the progress to TensorBoard so we create the appropriate callbacks for Keras*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "56yPnomQQqTv"
   },
   "outputs": [],
   "source": [
    "path_checkpoint = './gru_checkpoints/'\n",
    "\n",
    "callback_checkpoint = ModelCheckpoint(filepath=path_checkpoint,\n",
    "        monitor='val_loss',\n",
    "        verbose=1,\n",
    "        save_weights_only=True,\n",
    "        save_best_only=True)\n",
    "\n",
    "callback_early_stopping = EarlyStopping(monitor='val_loss',\n",
    "        patience=10, verbose=1)\n",
    "\n",
    "callback_tensorboard = TensorBoard(log_dir='./gru_logs/',\n",
    "        histogram_freq=0,\n",
    "        write_graph=False)\n",
    "\n",
    "# This callback reduces the learning-rate if the validation-loss has not improved as defined by `patience`.\n",
    "# The learning-rate will be reduced by a `factor` (by multiplying) but no more than `min_lr`.\n",
    "callback_reduce_lr = ReduceLROnPlateau(monitor='val_loss',\n",
    "        factor=0.3,\n",
    "        min_lr=1e-4,\n",
    "        patience=5,\n",
    "        min_delta = 1e-3,\n",
    "        verbose=1)\n",
    "\n",
    "keras_callbacks = [\n",
    "        callback_early_stopping,\n",
    "        #callback_tensorboard,\n",
    "        callback_reduce_lr,\n",
    "        callback_checkpoint\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KyBech-sQqTx"
   },
   "source": [
    "### Train the Recurrent Neural Network (RNN)\n",
    "\n",
    "*Note that within each `epoch` batch-generator will randomly select sub-sequences from the training-set, controlled by `steps_per_epoch`.*\n",
    "\n",
    "*Also note that the loss could become `NaN`, which can be resolved by restarting and running the Notebook again. But it may also be caused by your neural network architecture, learning-rate, batch-size, sequence-length, etc. in which case you may have to modify those settings.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 31187,
     "status": "ok",
     "timestamp": 1600920465975,
     "user": {
      "displayName": "Fatima Shiri",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjAn6eOEmJe2cvlJCvEwFwH_fJ_ccdyIze5N8aY6L8=s64",
      "userId": "07581629474593911406"
     },
     "user_tz": -600
    },
    "id": "EqgjA0asQqTx",
    "outputId": "7494ac93-3d86-458c-cca0-ec7089cb4105",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# fix random seed for (near) reproducibility\n",
    "np.random.seed(7)\n",
    "\n",
    "# Fit the model\n",
    "perform_indics = model.fit(x=generator,\n",
    "        epochs=epochs,\n",
    "        steps_per_epoch=steps_per_epoch,\n",
    "        validation_data=validation_data,\n",
    "        callbacks=keras_callbacks,\n",
    "        verbose=1 # Use 0 or 2 to speed up\n",
    "        )\n",
    "\n",
    "# Add performance history\n",
    "rnn_hist = collect_hist(rnn_hist, perform_indics.history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kgNWn4BIQqTz"
   },
   "source": [
    "*Plot training performance*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 31475,
     "status": "ok",
     "timestamp": 1600920466981,
     "user": {
      "displayName": "Fatima Shiri",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjAn6eOEmJe2cvlJCvEwFwH_fJ_ccdyIze5N8aY6L8=s64",
      "userId": "07581629474593911406"
     },
     "user_tz": -600
    },
    "id": "TsHkxvDjQqTz",
    "outputId": "72df6a23-9a70-4bb3-b85f-da6cbd79735c",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_hist(rnn_hist, xsize=10, ysize=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pCJgNC8BQqT1"
   },
   "source": [
    "### Load checkpoint\n",
    "\n",
    "*As we used ModelCheckpoint callback, we can reload the last saved checkpoint, which had the best performance on the validation set*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "63wz92rhQqT2"
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    model.load_weights(path_checkpoint)\n",
    "except Exception as error:\n",
    "    print(\"Error trying to load checkpoint.\")\n",
    "    print(error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sFsMtpcIQqT3"
   },
   "source": [
    "## Performance\n",
    "\n",
    "*Training performance*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 29976,
     "status": "ok",
     "timestamp": 1600920467271,
     "user": {
      "displayName": "Fatima Shiri",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjAn6eOEmJe2cvlJCvEwFwH_fJ_ccdyIze5N8aY6L8=s64",
      "userId": "07581629474593911406"
     },
     "user_tz": -600
    },
    "id": "QExzIaDJQqT3",
    "outputId": "f9dc999f-b013-4452-a2ca-852bda725a5e"
   },
   "outputs": [],
   "source": [
    "result = model.evaluate(x=np.expand_dims(x_train_scaled, axis=0),\n",
    "                        y=np.expand_dims(y_train_scaled, axis=0))\n",
    "# We have several metrics so we want to show their names\n",
    "print()\n",
    "for res, metric in zip(result, model.metrics_names):\n",
    "    print(\"{0}: {1:.5f}\".format(metric, res))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nwm9nLg8QqT5"
   },
   "source": [
    "*Test performance*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 29291,
     "status": "ok",
     "timestamp": 1600920467271,
     "user": {
      "displayName": "Fatima Shiri",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjAn6eOEmJe2cvlJCvEwFwH_fJ_ccdyIze5N8aY6L8=s64",
      "userId": "07581629474593911406"
     },
     "user_tz": -600
    },
    "id": "_kaijphfQqT5",
    "outputId": "467d57ce-ac46-4c30-8056-0d0c6cfe461c"
   },
   "outputs": [],
   "source": [
    "result = model.evaluate(x=np.expand_dims(x_test_scaled, axis=0),\n",
    "                        y=np.expand_dims(y_test_scaled, axis=0))\n",
    "# We have several metrics so we want to show their names\n",
    "print()\n",
    "for res, metric in zip(result, model.metrics_names):\n",
    "    print(\"{0}: {1:.5f}\".format(metric, res))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yB-yMWu_QqT7"
   },
   "source": [
    "## Generate predictions\n",
    "\n",
    "*This helper-function plots the predicted and true output-events*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ydvgBLsjQqT8"
   },
   "outputs": [],
   "source": [
    "# Plot the predicted and true output-events.\n",
    "\n",
    "def plot_comparison(start_idx, length=100, train=True, xlim=None, ylim=None):\n",
    "    \"\"\"\n",
    "    :param start_idx: Start-index for the time-series.\n",
    "    :param length: Sequence-length to process and plot.\n",
    "    :param train: Boolean whether to use training- or test-set.\n",
    "    \"\"\"\n",
    "    \n",
    "    if train:\n",
    "        # Use training-data.\n",
    "        x = x_train_scaled\n",
    "        y_true = y_train\n",
    "    else:\n",
    "        # Use test-data.\n",
    "        x = x_test_scaled\n",
    "        y_true = y_test\n",
    "    \n",
    "    # End-index for the sequences.\n",
    "    end_idx = start_idx + length\n",
    "    \n",
    "    # Select the sequences from the given start-index and\n",
    "    # of the given length.\n",
    "    x = x[start_idx:end_idx]\n",
    "    y_true = y_true[start_idx:end_idx]\n",
    "    \n",
    "    # Input-events for the model.\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "\n",
    "    # Use the model to predict the output-events.\n",
    "    y_pred = model.predict(x)\n",
    "    \n",
    "    # The output of the model is between 0 and 1.\n",
    "    # Do an inverse map to get it back to the scale\n",
    "    # of the original data-set.\n",
    "    y_pred_rescaled = y_scaler.inverse_transform(y_pred[0])\n",
    "    \n",
    "    # For each output-event.\n",
    "    for event in range(len(labels)):\n",
    "        # Get the output-event predicted by the model.\n",
    "        event_pred = y_pred_rescaled[:, event]\n",
    "        \n",
    "        # Get the true output-event from the data-set.\n",
    "        event_true = y_true[:, event]\n",
    "\n",
    "        # Make the plotting-canvas bigger.\n",
    "        plt.figure(figsize=(15,5))\n",
    "        \n",
    "        # Plot and compare the two events.\n",
    "        plt.plot(event_true, label='true')\n",
    "        plt.plot(event_pred, label='pred')\n",
    "        \n",
    "        # Plot grey box for warmup-period.\n",
    "        p = plt.axvspan(0, warmup_steps, facecolor='black', alpha=0.15)\n",
    "        \n",
    "        # Plot labels etc.\n",
    "        if (xlim): plt.xlim(xlim)\n",
    "        if (ylim): plt.ylim(ylim)\n",
    "        plt.ylabel(labels[event])\n",
    "        plt.legend()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zN3KGRaMQqT9"
   },
   "source": [
    "*Plot predicted output-events, which show only output-events and not the input-events used to predict the output-events. The `time-shift` between the input-events and the output-events is held fixed as defined in the `horizon` variable. So the x-axis merely shows how many time-steps of the input-events have been seen by the predictive model so far.*\n",
    "\n",
    "*The prediction is not very accurate for the initial time period because the model has seen very little input-data.\n",
    "The model needs to \"warm up\" first and so we ignore this \"warmup-period\" (shown as a grey box) in loss calculation.*\n",
    "\n",
    "**Example from the training data**\n",
    "\n",
    "*Change the ylim=(yfrom, yto) and xlim=(xfrom, xto) to zoom in on the relevant parts of the chart.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 320
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 27372,
     "status": "ok",
     "timestamp": 1600920467729,
     "user": {
      "displayName": "Fatima Shiri",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjAn6eOEmJe2cvlJCvEwFwH_fJ_ccdyIze5N8aY6L8=s64",
      "userId": "07581629474593911406"
     },
     "user_tz": -600
    },
    "id": "IBbHGdedQqT9",
    "outputId": "96fee664-f270-4b30-e084-eb9bd5a066cb",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# If you do see anything, delete ylim parameter\n",
    "plot_comparison(start_idx=0, length=3000, train=True, ylim=(20,250))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Naub66YoQqT_"
   },
   "source": [
    "**Example from test data**\n",
    "\n",
    "*Change the ylim=(yfrom, yto) and xlim=(xfrom, xto) to zoom in on the relevant parts of the chart.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 322
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 27028,
     "status": "ok",
     "timestamp": 1600920468280,
     "user": {
      "displayName": "Fatima Shiri",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjAn6eOEmJe2cvlJCvEwFwH_fJ_ccdyIze5N8aY6L8=s64",
      "userId": "07581629474593911406"
     },
     "user_tz": -600
    },
    "id": "B_UwSpsRQqT_",
    "outputId": "6b215050-f0fd-4e28-dfdd-808042850baa",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# If you do see anything, delete ylim parameter\n",
    "plot_comparison(start_idx=0, length=1500, train=False, ylim=(50, 320))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2BL1Tr8tQqUB"
   },
   "source": [
    "<br>**All done! Your report follows.**\n",
    "<hr style=\"height:1px;border:none;color:#333;background-color:#333;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nFLbpkEUQqUC"
   },
   "source": [
    "# RNN models, experiments and their results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1iyj2t95QqUC"
   },
   "source": [
    "## Reflection on experience gained in deep learning (as related to the entire module 3)\n",
    "\n",
    "<font color=\"red\">**Provide your reflection here.**</font>\n",
    "\n",
    "*Summarise the lessons learnt in module 3 on Deep Learning. List or tabulate the models you have experimented with. Optionally, compare and contrast their characteistics and the methods of their training (e.g. in the same table). Discuss the strengths and weaknesses of each of the DL approaches used in this module. Any recommendations for the future?*\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IENU3oE8QqUC"
   },
   "source": [
    "## RNN analysis and recommendation (as related to this notebook)\n",
    "\n",
    "<font color=\"red\">**Provide your analysis here.**</font>\n",
    "\n",
    "*In a paragraph discuss your results with RNN models. Identify the strengths and weaknesses of the selected models. Which model would you recommend as a portfolio management solution and why.*\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Pxyw_SqNQqUC"
   },
   "source": [
    "## Summary of RNN experimental results\n",
    "\n",
    "<font color='red'>**Complete this table with the summary of all your experimental results.**</font><br>\n",
    "**Work in the order of tasks listed at top of this notebook. Example of table entry has been included.**\n",
    "\n",
    "*Performance is measured as MAE comparing the the original and poredicted stock price.*\n",
    "\n",
    "| Model# | Run# | Batch | Seq | Epochs | Steps/Epoch | Stopped/Epochs | Optimiser | LR reduce factor | Train MAE | Valid MAE |\n",
    "| :- | :-: | :-: | :-: | :-: | :-: | :-: | :- | -: | -: | -: |\n",
    "| rnn_model_gru_sigmoid | 1 | 256 | 42 | 50 | 100 | 50/50 | SGD(lr=0.05, momentum=0.1, nesterov=False) | 0.3 | 0.02274 | 0.03080 |\n",
    "| xxx | xxx | xxx | xxx | xxx | xxx | xxx | *Replace the contents with your experimental results* | xxx | xxx | xxx |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "g5ZDJ_ZtQqUD"
   },
   "source": [
    "## Details of RNN model training runs and test results\n",
    "<font color=\"red\">**Provide details of the best models, within each category of your tasks, their training runs and test results.**</font><br>\n",
    "**Example of a training and test run record has been included.**\n",
    "\n",
    "***\n",
    "\n",
    "***rnn_model_gru_sigmoid, run #1:***<pre>\n",
    "*Brief model description goes here.*\n",
    "*Also what is special about this run.*\n",
    "\n",
    "**Data**\n",
    "stocks = ['Date', 'Day', 'AMZN', 'GOOGL', 'HPQ']\n",
    "labels = ['HPQ']\n",
    "horizon = 2\n",
    "\n",
    "**Performance**\n",
    "Train MAE: 0.02274\n",
    "Valid MAE: 0.03080\n",
    "\n",
    "**Training history and results**</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cN8XHqgvQqUD"
   },
   "source": [
    "![stock_hpq_perf_loss.png](attachment:stock_hpq_perf_loss.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Y1WNP-kiQqUE"
   },
   "source": [
    "![stock_hpq_perf_mae.png](attachment:stock_hpq_perf_mae.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "j4irZDYoQqUF"
   },
   "source": [
    "<center><i>Prediction on Training Data</i></center>\n",
    "\n",
    "![stock_hpq_pred_train.png](attachment:stock_hpq_pred_train.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DOJXxMSFQqUF"
   },
   "source": [
    "<center><i>Prediction on Test Data</i>\n",
    "\n",
    "![stock_hpq_pred_test.png](attachment:stock_hpq_pred_test.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pkF6YCUlQqUF"
   },
   "source": [
    "***\n",
    "\n",
    "***Another model, run #2:***<pre>\n",
    "</pre>\n",
    "\n",
    "***"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "anaconda-cloud": {},
  "colab": {
   "collapsed_sections": [],
   "name": "MIS780W10-Lab-RNN-Stock-v4.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
